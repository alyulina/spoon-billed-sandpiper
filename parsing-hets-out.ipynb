{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing the output of Fedya's code for the stint and the sandpiper to get heterozygosity averages\n",
    "# averaging over the last 100 time points for the stint\n",
    "\n",
    "# see ../ver14 for potentially helpful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0, -2, -4]\n",
    "beta = [0, 1000, 3000, 5000, 7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RNS_input.txt') as f: # should be the same for both\n",
    "    points = [['mu=' + x.split()[0], 'sigma=' + x.split()[1], 'alpha=' + x.split()[2], 'beta=' + x.split()[3]] for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "rns_pop_size = 5000\n",
    "n = 100 # how many time points to average over\n",
    "\n",
    "hets_rns = []; pols_rns = []\n",
    "\n",
    "c = 0\n",
    "for p in points:\n",
    "        \n",
    "    with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/rns/RNSv22_' + '_'.join(p) + '.txt') as f:\n",
    "        lines_rns = f.readlines()\n",
    "        \n",
    "        ind = [lines_rns.index(x) for x in lines_rns if 'generation\\t29999' in x] \n",
    "        lines = []\n",
    "        for i in ind:\n",
    "            lines.extend(lines_rns[i - n : i])\n",
    "                   \n",
    "        avg_het_2pq = np.mean([float(x.split()[11]) for x in lines])    \n",
    "        avg_dens = np.mean([(float(x.split()[9]) + 2 * float(x.split()[7])) for x in lines]) / rns_pop_size # hetero + 2 * homo; this is normalized by genome size inside the program; needs to be normalized by population size though\n",
    "        \n",
    "        hets_rns.append(' '.join(p).replace('=', ' ') + ' het ' + '{:.12f}'.format(avg_het_2pq) + '\\n')\n",
    "        pols_rns.append(' '.join(p).replace('=', ' ') + ' dens ' + '{:.12f}'.format(avg_dens) + '\\n')\n",
    "        \n",
    "        if c % 10 == 0:\n",
    "            print(c)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/rns-hets-points_rns_avg-het.txt', 'w+') as o:\n",
    "    o.writelines(hets_rns)\n",
    "with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/rns-hets-points_rns_pols.txt', 'w+') as o:\n",
    "    o.writelines(pols_rns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/out/rns_points_rns_avg-het_alpha=' + '{:.1f}'.format(a) + '_beta=' + '{:.0f}'.format(b) + '.txt', 'w+') as o:\n",
    "            o.writelines([x.replace('mu', '').replace('sigma', '').replace('alpha', '').replace('beta', '') for x in hets_rns if 'alpha ' + '{:.1f}'.format(a) + ' beta ' + '{:.0f}'.format(b) + ' ' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/out/rns_points_rns_pols_alpha=' + '{:.1f}'.format(a) + '_beta=' + '{:.0f}'.format(b) + '.txt', 'w+') as o:\n",
    "            o.writelines([x.replace('mu', '').replace('sigma', '').replace('alpha', '').replace('beta', '') for x in pols_rns if 'alpha ' + '{:.1f}'.format(a) + ' beta ' + '{:.0f}'.format(b) + ' ' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "sbs_pop_size = 90\n",
    "\n",
    "hets_sbs = []; pols_sbs = []\n",
    " \n",
    "c = 0\n",
    "for p in points:\n",
    "                \n",
    "    with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/sbs/SBSv22_' + '_'.join(p) + '.txt') as f:\n",
    "        lines_sbs = f.readlines()\n",
    "                    \n",
    "        lines = [x for x in lines_sbs if 'generation_decline\\t564' in x]\n",
    "                   \n",
    "        avg_het_2pq = np.mean([float(x.split()[11]) for x in lines])\n",
    "        avg_dens = np.mean([(float(x.split()[9]) + 2 * float(x.split()[7])) for x in lines]) / sbs_pop_size # hetero + 2 * homo; this is normalized by genome size inside the program; needs to be normalized by population size though\n",
    "                            \n",
    "        hets_sbs.append(' '.join(p).replace('=', ' ') + ' het ' + '{:.12f}'.format(avg_het_2pq) + '\\n')\n",
    "        pols_sbs.append(' '.join(p).replace('=', ' ') + ' dens ' + '{:.12f}'.format(avg_dens) + '\\n')\n",
    "        \n",
    "        if c % 10 == 0:\n",
    "            print(c)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/rns-hets-points_sbs_avg-het.txt', 'w+') as o:\n",
    "    o.writelines(hets_sbs)\n",
    "with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/rns-hets-points_sbs_pols.txt', 'w+') as o:\n",
    "    o.writelines(pols_sbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/out/rns_points_sbs_avg-het_alpha=' + '{:.1f}'.format(a) + '_beta=' + '{:.0f}'.format(b) + '.txt', 'w+') as o:\n",
    "            o.writelines([x.replace('mu', '').replace('sigma', '').replace('alpha', '').replace('beta', '') for x in hets_sbs if 'alpha ' + '{:.1f}'.format(a) + ' beta ' + '{:.0f}'.format(b) + ' ' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        with open('/nfs/scistore08/kondrgrp/alyulina/sandpiper/dynamics/h=sigm/ver22/out/rns_points_sbs_pols_alpha=' + '{:.1f}'.format(a) + '_beta=' + '{:.0f}'.format(b) + '.txt', 'w+') as o:\n",
    "            o.writelines([x.replace('mu', '').replace('sigma', '').replace('alpha', '').replace('beta', '') for x in pols_sbs if 'alpha ' + '{:.1f}'.format(a) + ' beta ' + '{:.0f}'.format(b) + ' ' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
